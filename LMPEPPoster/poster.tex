\documentclass[orientation=landscape]{tikzposter}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{adjustbox}

\geometry{paperwidth=48in,paperheight=36in}
\makeatletter
\setlength{\TP@visibletextwidth}{\textwidth-2\TP@innermargin}
\setlength{\TP@visibletextheight}{\textheight-2\TP@innermargin}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%			Title and Authors			%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\parbox{\linewidth}{\centering On Modifications to Laguerre's Method and the Polynomial Eigenvalue Problem}}
\author{Thomas R. Cameron* \& Nikolas I. Steckley**}
\institute{Davidson College* \& DiscoverOrg LLC.**}
\usetheme{Rays}
\usebackgroundstyle{Default}
\usetitlestyle{Default}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%			Main Document				%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
	\maketitle
	%%%	Abstract	%%%
	\block{Abstract}{Laguerre's method has long been recognized for its strong virtues when computing the roots of a polynomial. Over the years, many modifications to Laguerre's method have been suggested in an attempt to improve its convergence rate and to avoid multiple convergence to a simple root. Now, we present a modification to Laguerre's method for the simultaneous convergence of all roots of a polynomial. Multiple numerical experiments verify both the accuracy and efficiency of this algorithm, and we provide comparisons to other root finding methods, such as PZEROS and AMVW. Immediate future research includes applying this method to the polynomial eigenvalue problem, where it is effective for both large degree problems and the Tridiagonal problem.}
	%%%	Column 1	%%%
	\begin{columns}
		\column{0.333}
		%%%	Introduction	%%%
		\block{Introduction}{
			Let $p(\lambda)$ be a polynomial of degree $m$. Denote by $(z_{1},\ldots,z_{m})$ current approximations to the roots, $r_{1},\ldots,r_{m}$ of $p(\lambda)$. Then, for $j\in\{1,\dots,m\}$ define
			\[
			f_{j}(\lambda)=\frac{p(\lambda)}{\prod\limits_{\substack{i=1\\i\neq j}}^{m}(\lambda-z_{i})},
			\]
			and note that $f_{j}(\lambda)$ has the same roots as $p(\lambda)$. Further define
			\begin{equation}
			\begin{split}
			G_{j}(\lambda)&=\frac{f_{j}^{'}(\lambda)}{f_{j}(\lambda)}=\frac{p^{'}(\lambda)}{p(\lambda)}-\sum_{\substack{i=1\\i\neq j}}^{m}\frac{1}{\lambda-z_{i}}, \\
			H_{j}(\lambda)&=-\left(\frac{f_{j}^{'}(\lambda)}{f_{j}(\lambda)}\right)^{'}=-\left(\frac{p^{'}(\lambda)}{p(\lambda)}\right)^{'}-\sum_{\substack{i=1\\i\neq j}}^{m}\frac{1}{(\lambda-z_{i})^{2}}.
			\end{split}
			\end{equation}
			Then the jth root approximation is updated via the expression
			\begin{equation}\label{eq:lag2}
			\hat{z}_{j}=z_{j}-L_{m}(z_{j}),
			\end{equation}
			where the modified Laguerre updated is defined by
			\begin{equation}
			L_{m}(z_{j})=\frac{m}{G_{j}(z_{j})\pm\sqrt{(m-1)(mH_{j}(z_{j})-G_{j}^{2}(z_{j}))}},
			\end{equation}
			and the sign is chosen to maximize the magnitude of the denominator. \\
			The removal of previously computed roots is a well known modification of Laguerre's method and has been employed in~\cite{Lancaster1966,Parlett1964}. Here, we create poles at $z_{1},\ldots,z_{j-1},z_{j+1},\ldots,z_{m}$ in order to direct the Laguerre iteration away from other root approximations. A similar idea was used by Aberth to modify Newton's method~\cite{Aberth1973}. This makes for an algorithm that simultaneously approximates all roots of a polynomial. 
		}
		%%%	Algorithm Outline	%%%
		\block{Algorithm Outline}{
			For $j=1,\ldots,m$, the $jth$ root approximation is updated via (2), provided that it is not already close enough to the root $r_{j}$. The iteration can be implemented in either a Jacobi style (can be parallelized) or in a Gauss-Seidel style (experiences slightly faster convergence). Our current algorithm (DSLM) uses a Gauss-Seidel iteration style and has the following attributes.\\
			\textbf{Order of Convergence.}	Locally, if the root is simple, convergence is quartic; otherwise it is linear. \\
			\textbf{Cost Complexity.}	The computation of both expressions in (1) requires the evaluation of $p(\lambda)$, $p^{'}(\lambda)$, and $p^{''}(\lambda)$, along with the evaluation of two sums; this can be done using Horner's rule in $O(m)$ time. The convergence of all roots requires $O(m)$ iterations, it follows that DSLM can compute all root approximations in $O(m^{2})$ time. \\
			\textbf{Avoiding Overflow.}	If $|z_{j}|>1$, then the computation of both expressions in (1) is slightly modified using the reversal polynomial of $p(\lambda)$ in order to avoid the potential overflow in Horner's rule.
		}
		%%%	Column 2	%%%	
		\column{0.333}
		%%%	Initial Estimates		%%%
		\block{Initial Estimates}{
			Let $p(\lambda)=\sum_{i=0}^{m}a_{i}\lambda^{i}$, where $a_{0}a_{m}\neq 0$. The \emph{Newton polygon} associated with this polynomial is the upper convex hull of the discrete set $\{(i,\log|a_{i}|\colon~i=0,1,\ldots,m\}$. Let $0=k_{0}<k_{1}<\cdots<k_{q}=m$ denote the abscissas of the vertices of the Newton polygon, and define the radii
			\[
			\mu_{i}=\left|\frac{a_{k_{i-1}}}{a_{k_{i}}}\right|^{\frac{1}{k_{i}-k_{i-1}}},~(i=1,\ldots,q).
			\]
			Then, $(k_{i}-k_{i-1})$ evenly distributed points are placed on circles centered at $0$ with radius $\mu_{i}$. These points constitute our initial estimates to the roots of $p(\lambda)$. Furthermore, these points are guaranteed to lie within the Pellet bounds for the polynomial $p(\lambda)$, and can be computed in $O(m\log m)$ time~\cite{Bini1996}.
		}
		%%%	Stopping Criteria	%%%
		\block{Stopping Criteria}{
			It follows from~\cite{Tisseur2000}[Lemma 3] that the backward error in the root approximation $z_{j}$ is bounded above by
			\[
				b(z_{j})=\frac{|p(z_{j})|}{\sum\limits_{i=0}^{m}|a_{i}||z_{j}|^{i}}.
			\]
			\textbf{Criterion 1:}	If $b(z_{j})<\epsilon$, where $\epsilon$ denotes double precision unit roundoff, then we say that the approximation $z_{j}$ has converged.\\
			If Criterion 1 does not hold, then we compute the modified Laguerre update (3).\\
			\textbf{Criterion 2:}	If $|L_{m}(z_{j})|<\epsilon|z_{j}|$, then no relatively significant contribution will be made by $L_{m}(z_{j})$ and we say that the approximation $z_{j}$ has converged.\\
			 If Criterion 2 does not hold, then we update $z_{j}$ via (2). 
		}
		%%%	Comparison to Aberth and Laguerre	%%%
		\block{Comparison to Aberth and Laguerre}{
			\begin{minipage}{0.45\linewidth}
			Elapsed time comparisons are made between our modified Laguerre method, the standard Laguerre method, and the Aberth method. The initial conditions and stopping criteria are the same for all methods. For each Degree, there are $25$ different random polynomials created and the average elapsed time to compute the roots of each polynomial is recorded. 
			\end{minipage}\hfill
			\begin{adjustbox}{valign=t}
			\begin{minipage}[t]{0.55\linewidth}
			\centering
			\vspace*{-6.5em}
			\includegraphics[scale=1]{../develop/tests/diagrams/testMethods.pdf}
			\end{minipage}
			\end{adjustbox}
		}
		%%%	Column 3	%%%
		\column{0.333}
		%%%	Comparison to PZEROS and AMVW	%%%
		\block{Comparison to PZEROS  and AMVW}{
			%%%	Test 1	%%%
			\begin{minipage}{0.45\linewidth}
			\textbf{Random Polynomial Tests.} Elapsed time and backward error comparisons are made between our method (DSLM), PZEROS~\cite{Bini1996}, and AMVW~\cite{Aurentz2015}. For each degree, there are $25$ different random polynomials created and the average elapsed time to compute the roots of each polynomial is recorded. In addition, the average of the maximum backward error for the roots of each polynomial is recorded.
			\end{minipage}\hfill
			\begin{adjustbox}{valign=t}
			\begin{minipage}[t]{0.55\linewidth}
			\centering
			\vspace*{-7em}
			\includegraphics[scale=1.0]{../develop/tests/diagrams/testComparison1.pdf}
			\end{minipage}
			\end{adjustbox}
			%%%	Test 2	%%%
			\begin{minipage}{0.45\linewidth}
			\textbf{Select Polynomial Tests.}
			Relative forward error comparisons are made for the roots of the following polynomials.
			\scalebox{0.5}{
			\begin{tabular}{c | c | c | c}
			Test No. & Description & Deg. & Roots\\
			\hline
			1 & Wilkinson & 10 & $1,2,\ldots,10$\\
			2 & Wilkinson & 15 & $1,2,\ldots,15$\\
			3 & Wilkinson & 20 & $1,2,\ldots,20$\\
			4 & scaled and shifted Wilkinson & 20 & $-2.1,-1.9,\ldots,1.7$\\
			5 & reverse Wilkinson & 10 & $1,1/2,\ldots,1/10$\\
			6 & reverse Wilkinson & 15 & $1,1/2,\ldots,1/15$\\
			7 & reverse Wilkinson & 20 & $1,1/2,\ldots,1/20$\\
			8 & prescribed roots of varying scale & 20 & $2^{-10},2^{-9},\ldots,2^{9}$\\
			9 & prescribed roots of varying scale - 3 & 20 & $(2^{-10}-3),(2^{-9}-3),\ldots,(2^{9}-3)$\\
			10 & Chebyshev polynomial & 20 & $\cos(\frac{2j-1}{40}\pi)$\\
			\end{tabular}}
			\end{minipage}\hfill
			\begin{adjustbox}{valign=t}
			\begin{minipage}[t]{0.55\linewidth}
			\centering
			\vspace*{-4em}
			\includegraphics[scale=1.7]{../develop/tests/diagrams/testComparison2.pdf}
			\end{minipage}
			\end{adjustbox}
		}
		\block{Conclusion}{
			Future research includes applying this modified Laguerre method to the polynomial eigenvalue problem, as was done in~\cite{Lancaster1966,Parlett1964}. In addition, we are interested in developing a parallelized version of DSLM using the Jacobi style iteration. 
			%%%	References	%%%
			\bibliographystyle{siam}
			\bibliography{Bibliography}		
		}
	\end{columns}
\end{document}